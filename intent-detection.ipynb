{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Détection d'intentions dans les requêtes client**"
      ],
      "metadata": {
        "id": "II6k628TVrWL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\newpage\n",
        "## Table des matières\n",
        "\n",
        "- [1. Introduction](#introduction)\n",
        "    - [1.1. Contexte du projet](#11-contexte-du-projet)\n",
        "    - [1.2. Objectifs du projet](#12-objectifs-du-projet)\n",
        "    - [1.3. Résumé des étapes du processus](#13-résumé-des-étapes-du-processus)\n",
        "\n",
        "- [2. Théorie de base](#théorie-de-base)\n",
        "    - [2.1. Qu'est-ce que la classification de texte ?](#21-quest-ce-que-la-classification-de-texte)\n",
        "    - [2.2. Modèles pré-entraînés et transfert learning](#22-modèles-pré-entraînés-et-transfert-learning)\n",
        "    - [2.3. Le modèle BERT pour la classification de texte](#23-le-modèle-bert-pour-la-classification-de-texte)\n",
        "\n",
        "- [3. Importer les dépendances et préparer l'environnement](#importer-les-paquets-et-préparer-lenvironnement)\n",
        "    - [3.1. Description des bibliothèques nécessaires](#31-description-des-bibliothèques-nécessaires)\n",
        "    - [3.2. Installation des dépendances](#32-installation-des-dépendances)\n",
        "    - [3.3. Importer les dépendances](#33-importer-les-dépendances)\n",
        "    - [3.4. Configuration de l'appareil](#34-configuration-de-l-appareil)\n",
        "\n",
        "- [4. Chargement des données](#chargement-des-données)\n",
        "\n",
        "- [5. Prétraitement des données](#prétraitement-des-données)\n",
        "    - [5.1 Initialisation du tokenizer](#51-initialisation-du-tokenizer)\n",
        "    - [5.2 Création d'une classe de jeu de données personnalisée](#52-création-dune-classe-de-jeu-de-données-personnalisée)\n",
        "    - [5.3. Création des DataLoaders](#53-création-des-dataLoaders)\n",
        "    - [5.4. Exploration et visualisation des données](#54-Exploration-et-visualisation-des-données)\n",
        "    - [5.5. Vérification des batchs](#55-vérification-des-batchs)\n",
        "\n",
        "- [6. Définition du modèle](#définition-du-modèle)\n",
        "    - [6.1. Choix du modèle BERT](#61-choix-du-modèle-bert)\n",
        "    - [6.2. Implémentation du modèle](#62-implémentation-du-modèle)\n",
        "\n",
        "- [7. Configurer l'optimiseur et la fonction de perte](#configurer-loptimiseur-et-la-fonction-de-perte)\n",
        "    - [7.1. Choix de l'optimiseur (AdamW)](#71-choix-de-loptimiseur-adamw)\n",
        "    - [7.2. Implémentation de l'optimiseur et du scheduler](#72-implémentation-de-l-optimiseur-et-du-scheduler)\n",
        "\n",
        "- [8. Définir la fonction d'entraînement](#définir-la-fonction-dentrainement)\n",
        "    - [8.1. Pourquoi une fonction d'entraînement ?](#81-pourquoi-une-fonction-d-entraînement-?)\n",
        "    - [8.2. Les bonnes pratiques](#82-les-bonnes-pratiques)\n",
        "    - [8.3. Implémentation de la fonction d'entraînement](#83-implémentation-de-la-fonction-d-entraînement)\n",
        "\n",
        "- [9. Définir la fonction d'évaluation](#définir-la-fonction-dévaluation)\n",
        "    - [9.1. Pourquoi une fonction d'évaluation ?](#91-pourquoi-une-fonction-d-évaluation-?)\n",
        "    - [9.2. Points clés de la fonction](#92-points-clés-de-la-fonction)\n",
        "    - [9.3. Implémentation de la fonction d'évaluation](#93-implémentation-de-la-fonction-d-évaluation)\n",
        "\n",
        "- [10. Exécution de la fonction d'entraînement et de validation](#exécution-de-la-fonction-dentraînement-et-de-validation)\n",
        "\n",
        "- [11. Évaluation finale sur les données de test](#évaluation-finale-sur-les-données-de-test)\n",
        "    - [11.1. Objectif](#111-objectif)\n",
        "    - [11.2. Étapes principales](#112-étapes-principales)\n",
        "    - [11.3. Implémentation](#113-implémentation)\n",
        "\n",
        "- [12. Test du modèle avec des données personnalisées](#test-du-modèle-avec-des-données-personnalisées)\n",
        "    - [12.1. Objectif](#121-objectif)\n",
        "    - [12.2. Étapes principales](#122-étapes-principales)\n",
        "    - [12.3. Implémentation](#123-implémentation)\n",
        "\n",
        "- [13. Conclusion](#conclusion)\n",
        "    - [13.1. Résumé du projet](#131-résumé-du-projet)\n",
        "    - [13.2. Performances du modèle](#132-Performances-du-modèle)\n",
        "    - [13.3. Points forts](#133-Points-forts)\n",
        "    - [13.4. Limites et pistes d'amélioration](#134-limites-et-pistes-damélioration)\n",
        "    - [13.5. Conclusion finale](#135-conclusion-finale)\n"
      ],
      "metadata": {
        "id": "15rpXo8k8Hpq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction"
      ],
      "metadata": {
        "id": "8mTHYbmpFy01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. Contexte du projet"
      ],
      "metadata": {
        "id": "Y4pieq1fF2jn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le traitement du langage naturel (NLP) est un domaine de l'intelligence artificielle (IA) qui permet aux machines de comprendre, d'interpréter et de générer du langage humain. Dans le contexte de l'assistance client, il est crucial de traiter rapidement et efficacement les demandes des clients, en particulier lorsqu'elles sont nombreuses et variées. Un modèle de traitement du langage naturel bien conçu peut permettre d'automatiser la classification des demandes d'assistance par intention, ce qui améliore la réactivité et la précision du service client.\n",
        "\n",
        "Ce projet se concentre sur la création d'un modèle capable de classer les demandes d'assistance client en différentes catégories d'intentions à l'aide d'un modèle pré-entraîné BERT, affiné pour cette tâche spécifique. L'objectif est d'améliorer l'efficacité des systèmes de support automatisés."
      ],
      "metadata": {
        "id": "_wVQMkmkF6LL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. Objectifs du projet"
      ],
      "metadata": {
        "id": "6j6gTIe3F9Xx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'objectif principal de ce projet est de développer un modèle de classification des intentions des demandes d'assistance client. Ce modèle aura pour but de :\n",
        "1. **Classifier les demandes d'assistance client** selon leurs intentions (par exemple : question sur un produit, problème de facturation, demande de support technique, etc.).\n",
        "2. **Améliorer l'efficacité des systèmes d'assistance automatisée**, permettant une réponse plus rapide et plus précise.\n",
        "3. **Utiliser le modèle pré-entraîné BERT** pour affiner un modèle sur les données spécifiques du projet, tout en réduisant le temps de formation nécessaire grâce au transfert d'apprentissage."
      ],
      "metadata": {
        "id": "ZYEHzBlpGBJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3. Résumé des étapes du processus"
      ],
      "metadata": {
        "id": "Fe2PnJ9MGD5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le processus de développement de ce projet peut être résumé en plusieurs étapes principales :\n",
        "1. **Importation des paquets et préparation de l'environnement** : Nous avons importé les bibliothèques nécessaires pour construire et entraîner notre modèle.\n",
        "2. **Chargement des données** : Nous avons chargé le jeu de données et divisé les données en ensembles d'entraînement et de test.\n",
        "3. **Prétraitement des données** : Nous avons préparé les données en tokenisant le texte et en créant des jeux de données adaptés à l'entraînement.\n",
        "4. **Définition du modèle** : Nous avons choisi un modèle pré-entraîné BERT et l'avons affiné pour notre tâche de classification.\n",
        "5. **Entraînement et évaluation du modèle** : Nous avons entraîné le modèle, suivi ses performances pendant l'entraînement, et avons évalué sa précision.\n",
        "6. **Création de l'interface web** : Enfin, nous avons créé une interface web simple pour permettre aux utilisateurs de tester le modèle avec leurs propres données.\n"
      ],
      "metadata": {
        "id": "4kyD6OpEGPBD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Concepts de Base et Théories Sous-jacentes"
      ],
      "metadata": {
        "id": "qxuDCEsX8J0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. Qu'est-ce que la classification de texte ?\n",
        "\n"
      ],
      "metadata": {
        "id": "9ZPaceGOGkue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La classification de texte est une tâche fondamentale en traitement du langage naturel (NLP) qui consiste à attribuer une ou plusieurs étiquettes ou catégories à un texte donné. Cela peut être utilisé dans divers domaines tels que la détection de spams, l'analyse des sentiments, la catégorisation de documents, et dans ce projet, pour la **classification des intentions des demandes d'assistance client**.\n",
        "\n",
        "Dans le contexte de ce projet, la classification de texte consiste à analyser les demandes d'assistance des clients et à déterminer l'intention sous-jacente de chaque demande (par exemple, une question sur un produit, une demande de support technique, etc.). Cela permet de faciliter l'automatisation des réponses dans les systèmes d'assistance."
      ],
      "metadata": {
        "id": "rxO1gqR_Gp_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. Modèles pré-entraînés et transfert learning"
      ],
      "metadata": {
        "id": "nrXx7dLAGt9i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le **transfert learning** est une technique puissante utilisée en apprentissage automatique, où un modèle préalablement entraîné sur une large quantité de données dans une tâche générique est réutilisé et adapté pour une tâche spécifique. Cette approche permet de réduire le temps et les ressources nécessaires à l'entraînement d'un modèle pour une tâche précise.\n",
        "\n",
        "Les **modèles pré-entraînés** sont des modèles qui ont été entraînés sur de vastes jeux de données et qui possèdent une connaissance générale du langage. Ces modèles peuvent être affinés pour s'adapter à des tâches spécifiques, telles que la classification de texte, avec une quantité de données beaucoup plus réduite. Le transfert learning permet ainsi de tirer parti de cette connaissance pour obtenir de bons résultats sur des tâches spécifiques sans avoir à réentraîner un modèle complet.\n"
      ],
      "metadata": {
        "id": "MoOYqmr7Gw_o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3. Le modèle BERT pour la classification de texte"
      ],
      "metadata": {
        "id": "InCegYDIG51i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BERT** (Bidirectional Encoder Representations from Transformers) est un modèle de langage pré-entraîné développé par Google, qui a révolutionné le domaine du NLP. Contrairement à d'autres modèles de langage qui traitent le texte de manière unidirectionnelle (de gauche à droite ou de droite à gauche), BERT prend en compte l'intégralité du contexte en lisant les deux directions simultanément.\n",
        "\n",
        "BERT est particulièrement efficace pour les tâches de classification de texte, car il est capable de capturer des relations complexes dans les séquences de texte. Dans ce projet, nous utilisons BERT pour affiner un modèle préexistant sur notre jeu de données spécifique, ce qui nous permet de bénéficier de ses performances exceptionnelles tout en minimisant le besoin de données d'entraînement massives.\n",
        "\n",
        "Le processus d'affinement de BERT pour une tâche spécifique consiste à ajouter des couches supplémentaires au modèle et à l'entraîner avec nos données de classification. Ce processus permet au modèle de mieux comprendre le contexte et les particularités de la tâche à accomplir.\n",
        "E"
      ],
      "metadata": {
        "id": "2XYLEzZmG8jp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Importer les dépendances et préparer l'environnement"
      ],
      "metadata": {
        "id": "o8hYXQwf8TMu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1. Description des bibliothèques nécessaires"
      ],
      "metadata": {
        "id": "HseP3aHaKOrH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans cette section, nous allons utiliser plusieurs bibliothèques Python pour construire, entraîner et évaluer notre modèle de classification de texte. Voici les principales bibliothèques nécessaires :\n",
        "\n",
        "- **PyTorch** : Un framework d'apprentissage profond très populaire qui nous permet de construire et d'entraîner des modèles de machine learning. PyTorch fournit des outils puissants pour travailler avec des tenseurs et optimiser nos modèles.\n",
        "- **Transformers** : Une bibliothèque développée par Hugging Face, qui fournit des implémentations de modèles pré-entraînés comme BERT, GPT-2, etc. Nous utiliserons cette bibliothèque pour charger et affiner le modèle BERT.\n",
        "- **Pandas** : Une bibliothèque de manipulation et d'analyse des données. Nous l'utiliserons pour charger et prétraiter nos données.\n",
        "- **NumPy** : Une bibliothèque essentielle pour les calculs numériques en Python, souvent utilisée avec Pandas et PyTorch.\n",
        "- **Matplotlib / Seaborn** : Pour la visualisation des données et l'analyse des résultats du modèle.\n",
        "- **Scikit-learn** : Une bibliothèque pour l'apprentissage machine qui nous permettra de calculer des métriques de performance telles que la précision, le rappel, la F1-score.\n"
      ],
      "metadata": {
        "id": "bsPIz1goKP7U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2. Installation des dépendances"
      ],
      "metadata": {
        "id": "gubB0Ov1K0WJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install transformers\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install seaborn\n",
        "!pip install scikit-learn"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-XhXTYgdK54k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3. Importer les dépendances"
      ],
      "metadata": {
        "id": "PhXYjFlAMtva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import random\n",
        "import logging"
      ],
      "metadata": {
        "id": "xKmglw3bMxsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4. Configuration de l'appareil"
      ],
      "metadata": {
        "id": "vAuajASZM2kA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "4mjXenX7M7a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8Gwrjxh1ND_W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Chargement des données"
      ],
      "metadata": {
        "id": "fpewRv6PLbKY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le jeu de données est une partie essentielle de ce projet, car il détermine la qualité et la portée du modèle de classification. Dans cette étape, nous utilisons le jeu de données public **CLINC OOS Plus**, qui contient des exemples d'intents pour les interactions client, répartis en ensembles d'entraînement, de validation et de test.\n",
        "\n",
        "Le processus inclut les étapes suivantes :\n",
        "1. Charger le jeu de données.\n",
        "2. Examiner la structure des données et la taille de chaque ensemble (train, validation, test).\n",
        "3. Inspecter quelques exemples pour comprendre le format et les intentions associées.\n",
        "4. Extraire et afficher les labels des intentions.\n",
        "5. Visualiser la répartition des intentions dans l'ensemble d'entraînement.\n",
        "6. Vérifier et gérer d'éventuels déséquilibres de classes."
      ],
      "metadata": {
        "id": "bmIrtpCxLkvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger le jeu de données CLINC OOS Plus\n",
        "from datasets import load_dataset\n",
        "import random\n",
        "\n",
        "dataset = load_dataset(\"clinc_oos\", \"plus\")"
      ],
      "metadata": {
        "id": "evXmaCmK5o6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérifier la structure des données\n",
        "print(\"Dataset structure:\", dataset)\n",
        "print(\"Training examples:\", len(dataset['train']))\n",
        "print(\"Validation examples:\", len(dataset['validation']))\n",
        "print(\"Test examples:\", len(dataset['test']))"
      ],
      "metadata": {
        "id": "7LkOJvah5uCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspecter quelques exemples pour comprendre la structure des données\n",
        "print(\"\\nSample training data:\")\n",
        "print(dataset['train'][0])  # Afficher le premier exemple\n",
        "print(dataset['train'][120])  # Afficher un autre exemple"
      ],
      "metadata": {
        "id": "iwI86PTn5xji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraire les labels des intentions\n",
        "intent_labels = dataset['train'].features['intent'].names\n",
        "print(\"\\nIntent Labels:\", intent_labels)"
      ],
      "metadata": {
        "id": "ORPQxoJu505U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher quelques exemples avec les labels d'intentions\n",
        "random_sample_idx = random.randint(1, len(dataset['train']))\n",
        "print(\"\\nSample training data with intent labels:\")\n",
        "for i in range(random_sample_idx, random_sample_idx + 3):\n",
        "    sample = dataset['train'][i]\n",
        "    text = sample['text']\n",
        "    intent_id = sample['intent']\n",
        "    intent_label = intent_labels[intent_id]\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Intent ID: {intent_id}, Intent Label: {intent_label}\")"
      ],
      "metadata": {
        "id": "QI05y3F153ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyser la répartition des classes dans l'ensemble d'entraînement\n",
        "train_intent_ids = [example['intent'] for example in dataset['train']]\n",
        "intent_counts = Counter(train_intent_ids)"
      ],
      "metadata": {
        "id": "GW-IoHbI6eZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualiser la répartition des classes\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar([intent_labels[i] for i in intent_counts.keys()], intent_counts.values(), color='skyblue')\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Répartition des labels d'intentions dans l'ensemble d'entraînement\")\n",
        "plt.xlabel(\"Labels d'intention\")\n",
        "plt.ylabel(\"Nombre d'exemples\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0wcxqQwe6fBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérification des classes minoritaires\n",
        "minority_classes = [intent_labels[i] for i, count in intent_counts.items() if count < 50]\n",
        "print(\"\\nClasses minoritaires détectées (moins de 50 exemples) :\", minority_classes)"
      ],
      "metadata": {
        "id": "neQlEDxM6hvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Prétraitement des données"
      ],
      "metadata": {
        "id": "9y4fXU_o8Ml8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le prétraitement des données est une étape cruciale pour convertir les textes en un format utilisable par le modèle de deep learning. Voici les étapes effectuées dans cette section :\n",
        "\n",
        "1. **Initialisation du tokenizer** : Utilisation du tokenizer `DistilBERT` pour convertir le texte brut en jetons.\n",
        "2. **Création d'une classe de dataset personnalisée** : Une classe spécifique est définie pour gérer les données du jeu CLINC150, incluant le texte, les intentions, et leurs représentations tokenisées.\n",
        "3. **Création des DataLoaders** : Les DataLoaders sont utilisés pour gérer efficacement les ensembles d'entraînement, de validation et de test.\n",
        "4. **Exploration et visualisation des données** : Visualisation des jetons et IDs pour un exemple spécifique.\n",
        "5. **Vérification des batchs** : Inspection d'un batch pour s'assurer que les données sont correctement préparées avant l'entraînement.\n"
      ],
      "metadata": {
        "id": "raBVWp0u8w57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1. Initialisation du tokenizer"
      ],
      "metadata": {
        "id": "Sa2shOdi86gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the tokenizer\n",
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "id": "Lnxy5GsR-7lQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define max token length for padding and truncation\n",
        "MAX_TOKEN_LENGTH = 128"
      ],
      "metadata": {
        "id": "q9mX314X_Wmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2. Création d'une classe de dataset personnalisée"
      ],
      "metadata": {
        "id": "rDPD6aHp_iIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CLINC150Dataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length=128):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Extract the text and intent from the dataset\n",
        "        text = self.data[idx]['text']\n",
        "        intent = self.data[idx]['intent']\n",
        "\n",
        "        # Tokenize the text with padding and truncation\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        # Return tokenized input IDs, attention mask, and intent label\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(intent, dtype=torch.long)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "KL_Lknpx_kZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3. Création des DataLoaders"
      ],
      "metadata": {
        "id": "rpcxqXwi_oKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def create_data_loader(data, tokenizer, batch_size=32, max_length=128):\n",
        "    # Instantiate the custom dataset\n",
        "    ds = CLINC150Dataset(data, tokenizer, max_length=max_length)\n",
        "    return DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# Create DataLoaders for training, validation, and test sets\n",
        "BATCH_SIZE = 32\n",
        "train_loader = create_data_loader(dataset['train'], tokenizer, batch_size=BATCH_SIZE)\n",
        "val_loader = create_data_loader(dataset['validation'], tokenizer, batch_size=BATCH_SIZE)\n",
        "test_loader = create_data_loader(dataset['test'], tokenizer, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "NFMzTaX4AAa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4. Exploration et visualisation des données"
      ],
      "metadata": {
        "id": "h5Roo2iZAjUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example text from training dataset\n",
        "example_text = dataset['train'][0]['text']\n",
        "tokens = tokenizer.tokenize(example_text)\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(f\"Example Text: {example_text}\")\n",
        "print(f\"Tokens: {tokens}\")\n",
        "print(f\"Token IDs: {token_ids}\")\n"
      ],
      "metadata": {
        "id": "ramYpuPvApFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.5. Vérification des batchs"
      ],
      "metadata": {
        "id": "_4Rt2kPGADV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first batch from the training DataLoader\n",
        "data = next(iter(train_loader))\n",
        "print(\"Sample batch from train_loader:\")\n",
        "print(\"Input IDs shape:\", data['input_ids'].shape)\n",
        "print(\"Attention Mask shape:\", data['attention_mask'].shape)\n",
        "print(\"Labels shape:\", data['labels'].shape)"
      ],
      "metadata": {
        "id": "2NoamXjUAYcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Définition du modèle\n"
      ],
      "metadata": {
        "id": "ANoFnaCgERQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1. Choix du modèle BERT"
      ],
      "metadata": {
        "id": "s2ZmQ6foEjx4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le modèle BERT (**Bidirectional Encoder Representations from Transformers**) est largement utilisé pour les tâches de traitement du langage naturel (NLP). Nous avons opté pour la version **DistilBERT**, une variante légère et rapide de BERT. Les raisons de ce choix incluent :\n",
        "\n",
        "1. **Efficacité computationnelle** : DistilBERT est environ 40% plus léger que BERT tout en conservant une grande partie de ses performances.\n",
        "2. **Adaptabilité** : DistilBERT peut être utilisé pour une variété de tâches NLP, y compris la classification de texte.\n",
        "3. **Pré-entraînement** : Le modèle est déjà pré-entraîné sur de vastes corpus textuels, ce qui le rend adapté pour le **fine-tuning** sur notre jeu de données.\n"
      ],
      "metadata": {
        "id": "tIEVGjKVF7dm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2. Implémentation du modèle"
      ],
      "metadata": {
        "id": "gessHoWyF_t9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous utilisons `DistilBERTForSequenceClassification` de la bibliothèque **Transformers** pour créer notre modèle. La tête de classification est ajustée en fonction du nombre de classes d'intention présentes dans notre jeu de données. Nous transférons ensuite le modèle sur le GPU (ou CPU) disponible et testons sa configuration.\n",
        "\n",
        "Voici les étapes principales :\n",
        "- Chargement du modèle pré-entraîné\n",
        "- Spécification du nombre de classes\n",
        "- Allocation du modèle sur le GPU/CPU\n",
        "- Inspection de la structure du modèle"
      ],
      "metadata": {
        "id": "3IZy5MdXGdCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import DistilBertForSequenceClassification"
      ],
      "metadata": {
        "id": "exx4pcAsGpeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Définir le nombre de classes d'intention\n",
        "num_labels = len(intent_labels)"
      ],
      "metadata": {
        "id": "_42RTYdUGrEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement et configuration du modèle\n",
        "try:\n",
        "    # Charger le modèle pré-entraîné DistilBERT avec une tête de classification\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(\n",
        "        'distilbert-base-uncased',  # Modèle BERT de base\n",
        "        num_labels=num_labels      # Spécifier le nombre de classes\n",
        "    )\n",
        "    print(\"Modèle chargé avec succès.\")\n",
        "except Exception as e:\n",
        "    print(f\"Erreur lors du chargement du modèle : {e}\")"
      ],
      "metadata": {
        "id": "WzbQdOpxEiw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Allocation sur l'appareil\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"Modèle initialisé sur : {device}\")"
      ],
      "metadata": {
        "id": "YdR8TQeGGx8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspection de la structure\n",
        "print(\"Architecture du modèle :\")\n",
        "print(model)"
      ],
      "metadata": {
        "id": "Jop4uMdOG2it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Configurer l'optimiseur et la fonction de perte"
      ],
      "metadata": {
        "id": "RJEQ31SZG-yT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1. Choix de l'optimiseur"
      ],
      "metadata": {
        "id": "igmv8X8SUZeJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'optimiseur **AdamW** (**Adam avec Weight Decay**) est une variante améliorée de l'algorithme Adam classique, conçue pour mieux s'adapter à l'entraînement des modèles de deep learning, en particulier ceux basés sur les transformeurs comme BERT. Les raisons principales pour son utilisation incluent :\n",
        "\n",
        "1. **Correction du biais de régularisation L2** :\n",
        "   - Contrairement à l'Adam standard, **AdamW** applique le **weight decay** (pénalisation de la norme des poids) de manière indépendante de l'étape de mise à jour des gradients. Cela permet une régularisation plus efficace et empêche les poids de croître indéfiniment.\n",
        "\n",
        "2. **Performance optimale pour les modèles NLP** :\n",
        "   - AdamW est le choix recommandé pour les modèles pré-entraînés tels que BERT, car il gère bien les petits taux d'apprentissage nécessaires à leur fine-tuning.\n",
        "\n",
        "3. **Contrôle précis des hyperparamètres** :\n",
        "   - Avec le poids de décroissance (`weight_decay`), nous pouvons réduire le surapprentissage, ce qui est essentiel pour les tâches sensibles comme la classification des intentions.\n",
        "\n",
        "### Implémentation de l'optimiseur et du scheduler\n",
        "\n",
        "Nous configurons également un **scheduler** pour ajuster dynamiquement le taux d'apprentissage pendant l'entraînement. Le scheduler utilise un échauffement (**warm-up**) au début pour stabiliser l'entraînement, suivi d'une décroissance progressive."
      ],
      "metadata": {
        "id": "qgp3kLWJUea-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2. Implémentation de l'optimiseur et du scheduler"
      ],
      "metadata": {
        "id": "gkIeJqpuWM2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous configurons également un **scheduler** pour ajuster dynamiquement le taux d'apprentissage pendant l'entraînement. Le scheduler utilise un échauffement (**warm-up**) au début pour stabiliser l'entraînement, suivi d'une décroissance progressive.\n"
      ],
      "metadata": {
        "id": "6mo_aXCqbpWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration de l'optimiseur\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),    # Paramètres du modèle\n",
        "    lr=2e-5,               # Taux d'apprentissage initial\n",
        "    weight_decay=0.01      # Régularisation L2 via weight decay\n",
        ")"
      ],
      "metadata": {
        "id": "0hbFBTeOb2Cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration du scheduler de taux d'apprentissage\n",
        "# Nombre d'époques d'entraînement\n",
        "num_epochs = 10\n",
        "\n",
        "# Calcul du nombre total d'étapes\n",
        "total_steps = len(train_loader) * num_epochs\n",
        "\n",
        "# Scheduler pour ajuster le taux d'apprentissage\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=total_steps // 10,  # Echauffement sur 10% des étapes\n",
        "    num_training_steps=total_steps       # Décroissance progressive\n",
        ")"
      ],
      "metadata": {
        "id": "7zIXJtwcb74g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Définir la fonction d'entraînement"
      ],
      "metadata": {
        "id": "wC_RM6QpfS_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.1. Pourquoi une fonction d'entraînement ?"
      ],
      "metadata": {
        "id": "5q8VG6zCfWcR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Une fonction d'entraînement est au cœur de tout processus d'apprentissage supervisé. Elle encapsule la logique pour entraîner un modèle sur une ou plusieurs époques, en effectuant les étapes suivantes :\n",
        "1. Passer les données d'entraînement à travers le modèle (**forward pass**).\n",
        "2. Calculer la perte (erreur entre les prédictions du modèle et les étiquettes réelles).\n",
        "3. Propager l'erreur à travers le modèle pour mettre à jour les poids (**backward pass**).\n",
        "4. Ajuster le taux d'apprentissage avec un **scheduler** pour stabiliser l'entraînement.\n"
      ],
      "metadata": {
        "id": "SJRzz_TBfaok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.2. Les bonnes pratiques"
      ],
      "metadata": {
        "id": "_sORbvZ_fk3w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour rendre l'entraînement plus robuste :\n",
        "- **Clipping des gradients** : Évite les explosions de gradients en limitant leur norme.\n",
        "- **Barre de progression** : La librairie `tqdm` aide à suivre l'avancement des époques.\n",
        "- **Gestion explicite des appareils** : Le modèle et les données sont déplacés vers le CPU ou GPU en fonction de la disponibilité.\n",
        "**bold text**"
      ],
      "metadata": {
        "id": "9aK72wwKfjzq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.3. Implémentation de la fonction d'entraînement"
      ],
      "metadata": {
        "id": "LBCSBOmpgL7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm  # Bibliothèque pour afficher une barre de progression\n",
        "\n",
        "def train_epoch(model, data_loader, optimizer, scheduler, device):\n",
        "    \"\"\"\n",
        "    Entraîne le modèle sur une époque.\n",
        "\n",
        "    Args:\n",
        "        model: Le modèle PyTorch à entraîner.\n",
        "        data_loader: DataLoader pour fournir des mini-batches de données.\n",
        "        optimizer: Optimiseur pour ajuster les poids.\n",
        "        scheduler: Scheduler pour mettre à jour le taux d'apprentissage.\n",
        "        device: Appareil utilisé pour l'entraînement (CPU ou GPU).\n",
        "\n",
        "    Returns:\n",
        "        Perte moyenne pour l'époque.\n",
        "    \"\"\"\n",
        "    model.train()  # Met le modèle en mode entraînement\n",
        "    total_loss = 0  # Cumul des pertes\n",
        "    progress_bar = tqdm(data_loader, desc=\"Training\")  # Barre de progression\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        # Déplacer les données vers l'appareil (GPU ou CPU)\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Remise à zéro des gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Forward pass (calcul des prédictions)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "        # Calcul de la perte\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward pass et clipping des gradients\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        # Mise à jour des paramètres du modèle\n",
        "        optimizer.step()\n",
        "\n",
        "        # Mise à jour du taux d'apprentissage\n",
        "        scheduler.step()\n",
        "\n",
        "        # Mise à jour de la barre de progression avec la perte actuelle\n",
        "        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "    # Retourne la perte moyenne de l'époque\n",
        "    return total_loss / len(data_loader)\n"
      ],
      "metadata": {
        "id": "w2_zNG4bgPpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Définir la fonction d'évaluation"
      ],
      "metadata": {
        "id": "ZhPhZVJQilRI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.1. Pourquoi une fonction d'évaluation ?"
      ],
      "metadata": {
        "id": "Yr5enWGfi9t8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'évaluation permet d'estimer les performances du modèle sur des données de validation ou de test, qui n'ont pas été utilisées lors de l'entraînement. Elle inclut les étapes suivantes :\n",
        "1. Calcul de la perte moyenne sur l'ensemble des données.\n",
        "2. Extraction des prédictions pour comparer avec les étiquettes réelles.\n",
        "3. Calcul de métriques importantes comme la précision et un rapport de classification."
      ],
      "metadata": {
        "id": "spHn3vhWjD5k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.2. Points clés de la fonction"
      ],
      "metadata": {
        "id": "_BjRL60tjIaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Mode évaluation (`model.eval()`)** : Désactive des couches comme Dropout et empêche le calcul des gradients.\n",
        "- **Pas de calcul des gradients** : Utilisation de `torch.no_grad()` pour économiser de la mémoire et accélérer l'exécution.\n",
        "- **Métriques de performance** : Précision (`accuracy_score`) et rapport détaillé (`classification_report`) pour comprendre les performances globales et par classe.\n",
        "- **Retour des prédictions (facultatif)** : Utile pour une analyse qualitative ou des visualisations.\n"
      ],
      "metadata": {
        "id": "lEfC-dcqjIHt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.3. Implémentation de la fonction d'évaluation"
      ],
      "metadata": {
        "id": "wY-15WzcjPz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate(model, data_loader, device, return_predictions=False):\n",
        "    \"\"\"\n",
        "    Évalue les performances du modèle sur un DataLoader donné.\n",
        "\n",
        "    Args:\n",
        "        model: Le modèle PyTorch à évaluer.\n",
        "        data_loader: DataLoader contenant les données à évaluer.\n",
        "        device: Appareil utilisé (CPU ou GPU).\n",
        "        return_predictions: Si True, retourne aussi les prédictions et étiquettes réelles.\n",
        "\n",
        "    Returns:\n",
        "        avg_loss: Perte moyenne sur l'ensemble des données.\n",
        "        accuracy: Précision globale.\n",
        "        report: Rapport de classification détaillé.\n",
        "        (Facultatif) predictions, actual_labels: Liste des prédictions et des étiquettes réelles.\n",
        "    \"\"\"\n",
        "    model.eval()  # Met le modèle en mode évaluation\n",
        "    predictions = []  # Liste pour stocker les prédictions\n",
        "    actual_labels = []  # Liste pour stocker les étiquettes réelles\n",
        "    total_loss = 0  # Somme des pertes\n",
        "\n",
        "    # Pas besoin de calculer les gradients en évaluation\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(data_loader, desc=\"Evaluating\"):  # Barre de progression\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Pass avant (forward pass)\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "            # Calculer la perte et l'ajouter au total\n",
        "            total_loss += outputs.loss.item()\n",
        "\n",
        "            # Récupérer les prédictions\n",
        "            _, preds = torch.max(outputs.logits, dim=1)  # Logits vers classes\n",
        "\n",
        "            # Stocker les prédictions et les étiquettes\n",
        "            predictions.extend(preds.cpu().tolist())\n",
        "            actual_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "    # Calculer les métriques finales\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    accuracy = accuracy_score(actual_labels, predictions)\n",
        "    report = classification_report(actual_labels, predictions)\n",
        "\n",
        "    if return_predictions:\n",
        "        return avg_loss, accuracy, report, predictions, actual_labels\n",
        "\n",
        "    return avg_loss, accuracy, report\n"
      ],
      "metadata": {
        "id": "kerXEITWjUHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Exécution de la fonction d'entraînement et de validation"
      ],
      "metadata": {
        "id": "_H3PQ5V3lnP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette section combine les fonctions d'entraînement et d'évaluation pour former le modèle sur les données d'entraînement et évaluer ses performances sur les données de validation à chaque époque.\n",
        "\n",
        "Les etapes principales:\n",
        "1. **Entraînement** : Utilisation de la fonction `train_epoch` pour mettre à jour les poids du modèle en minimisant la perte sur les données d'entraînement.\n",
        "2. **Validation** : Utilisation de la fonction `evaluate` pour mesurer les performances du modèle sur les données de validation, ce qui permet de détecter un éventuel sur-apprentissage (overfitting).\n",
        "3. **Suivi des performances** :\n",
        "   - Affichage des pertes et des métriques de chaque époque.\n",
        "   - Sauvegarde du meilleur modèle basé sur la précision de validation."
      ],
      "metadata": {
        "id": "GBoedjJYlpZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, train_loader, val_loader, optimizer, scheduler, device, num_epochs=3):\n",
        "    \"\"\"\n",
        "    Combine l'entraînement et l'évaluation pour plusieurs époques.\n",
        "\n",
        "    Args:\n",
        "        model: Modèle PyTorch à entraîner.\n",
        "        train_loader: DataLoader pour les données d'entraînement.\n",
        "        val_loader: DataLoader pour les données de validation.\n",
        "        optimizer: Optimiseur pour la mise à jour des poids.\n",
        "        scheduler: Scheduler pour ajuster le taux d'apprentissage.\n",
        "        device: Appareil utilisé (CPU ou GPU).\n",
        "        num_epochs: Nombre total d'époques d'entraînement.\n",
        "\n",
        "    Sauvegarde:\n",
        "        Le meilleur modèle basé sur la précision de validation.\n",
        "    \"\"\"\n",
        "    best_accuracy = 0  # Pour suivre la meilleure précision de validation\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "        # Étape d'entraînement\n",
        "        train_loss = train_epoch(model, train_loader, optimizer, scheduler, device)\n",
        "        print(f\"Training Loss: {train_loss:.4f}\")\n",
        "\n",
        "        # Étape de validation\n",
        "        val_loss, val_accuracy, val_report = evaluate(model, val_loader, device)\n",
        "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "        print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "        print(\"Validation Classification Report:\\n\", val_report)\n",
        "\n",
        "        # Sauvegarde du modèle si c'est le meilleur jusqu'ici\n",
        "        if val_accuracy > best_accuracy:\n",
        "            best_accuracy = val_accuracy\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            print(f\"New best model saved with accuracy: {best_accuracy:.4f}\")\n",
        "\n",
        "    print(\"\\nTraining and validation complete.\")\n",
        "    print(f\"Best validation accuracy achieved: {best_accuracy:.4f}\")\n",
        "\n",
        "# Exécution\n",
        "train_and_evaluate(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    device=device,\n",
        "    num_epochs=5\n",
        ")\n"
      ],
      "metadata": {
        "id": "SG-THGCCmNT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Évaluation finale sur les données de test"
      ],
      "metadata": {
        "id": "Nb33nMY_ntkY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.1. Objectif"
      ],
      "metadata": {
        "id": "EYlaXGn8nzag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'évaluation finale consiste à tester le modèle formé sur des données jamais vues (données de test) pour obtenir une mesure impartiale de ses performances. Cette étape produit des métriques complètes comme le rapport de classification, qui détaille la précision, le rappel et le score F1 pour chaque classe.\n"
      ],
      "metadata": {
        "id": "zRQqFMMeoB9o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.2. Étapes principales"
      ],
      "metadata": {
        "id": "qKW2WRQDoXru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Préparation du modèle** :\n",
        "   - Mettre le modèle en mode évaluation (`model.eval()`).\n",
        "   - Désactiver la propagation des gradients pour économiser de la mémoire et accélérer les calculs.\n",
        "\n",
        "2. **Prédictions** :\n",
        "   - Générer des prédictions pour chaque lot de données de test.\n",
        "   - Collecter les étiquettes prédites et les étiquettes réelles.\n",
        "\n",
        "3. **Calcul des métriques** :\n",
        "   - Utiliser `classification_report` de scikit-learn pour produire un rapport détaillé des performances.\n"
      ],
      "metadata": {
        "id": "1F9HkrWWoV47"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.3. Implémentation"
      ],
      "metadata": {
        "id": "dLRG6AhKoccH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def final_evaluation(model, test_loader, label_names):\n",
        "    \"\"\"\n",
        "    Évalue le modèle sur les données de test et génère un rapport de classification.\n",
        "\n",
        "    Args:\n",
        "        model: Modèle PyTorch entraîné.\n",
        "        test_loader: DataLoader contenant les données de test.\n",
        "        label_names: Liste des noms des classes cibles.\n",
        "\n",
        "    Affiche:\n",
        "        Rapport de classification comprenant la précision, le rappel et le score F1 pour chaque classe.\n",
        "    \"\"\"\n",
        "    model.eval()  # Met le modèle en mode évaluation\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Pas besoin de calculs de gradients lors de l'évaluation\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            # Récupérer les données du lot\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Passage avant\n",
        "            outputs = model(input_ids)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Obtenir les prédictions\n",
        "            preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            # Stocker les prédictions et les étiquettes réelles\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calculer le rapport de classification\n",
        "    report = classification_report(\n",
        "        all_labels,\n",
        "        all_preds,\n",
        "        target_names=label_names,\n",
        "        labels=list(range(len(label_names)))\n",
        "    )\n",
        "    print(\"Rapport de classification finale :\")\n",
        "    print(report)\n",
        "\n",
        "# Exécution de l'évaluation\n",
        "# Remplissez `label_names` avec les noms exacts de vos classes\n",
        "label_names = [f'intent_{i}' for i in range(151)]  # Exemple générique\n",
        "final_evaluation(model, test_loader, label_names)\n"
      ],
      "metadata": {
        "id": "TiTCfNIGogS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Test du modèle avec des données personnalisées"
      ],
      "metadata": {
        "id": "YsaUVqZsrAga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 12.1. Objectif"
      ],
      "metadata": {
        "id": "FmY26k4yrOZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette section permet de tester le modèle sur des données textuelles fournies directement par l'utilisateur. L'objectif est d'identifier l'intention (classe) prédite pour une phrase donnée."
      ],
      "metadata": {
        "id": "AkJB398UrRFf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 12.2. Étapes principales"
      ],
      "metadata": {
        "id": "moRdDHE-rVnS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Prétraitement du texte** :\n",
        "   - Tokenisation et mise en forme des données textuelles à l'aide du tokenizer pré-entraîné associé à DistilBERT.\n",
        "   - Ajout de padding et de troncature pour respecter les contraintes de longueur maximale.\n",
        "\n",
        "2. **Passage dans le modèle** :\n",
        "   - Utilisation du modèle en mode évaluation pour prédire la classe de l'intention.\n",
        "\n",
        "3. **Retour de l'intention prédite** :\n",
        "   - Extraction de la classe avec la probabilité la plus élevée et association à son étiquette."
      ],
      "metadata": {
        "id": "JlEkyWlrraEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 12.3. Implémentation"
      ],
      "metadata": {
        "id": "ujXRFqJYreGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_intent(text, model, tokenizer, device):\n",
        "    \"\"\"\n",
        "    Prédit l'intention d'une phrase donnée à l'aide du modèle entraîné.\n",
        "\n",
        "    Args:\n",
        "        text (str): Phrase d'entrée dont on veut prédire l'intention.\n",
        "        model: Modèle PyTorch pré-entraîné pour la classification d'intentions.\n",
        "        tokenizer: Tokenizer associé au modèle (de Hugging Face).\n",
        "        device: Dispositif (CPU ou GPU) sur lequel exécuter la prédiction.\n",
        "\n",
        "    Returns:\n",
        "        tuple: La classe prédite (int) et l'étiquette de l'intention (str).\n",
        "    \"\"\"\n",
        "    # Prétraitement du texte (tokenisation, padding, troncature)\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",  # Retourne des tenseurs PyTorch\n",
        "        truncation=True,      # Tronque si le texte dépasse la longueur maximale\n",
        "        padding=True,         # Ajoute du padding pour aligner les séquences\n",
        "        max_length=512        # Longueur maximale autorisée par le modèle\n",
        "    )\n",
        "\n",
        "    # Déplacement des tenseurs vers l'appareil approprié (GPU/CPU)\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    # Mettre le modèle en mode évaluation\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Passage avant dans le modèle\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Prédiction de la classe avec la probabilité maximale\n",
        "        predicted_class = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    # Correspondance entre la classe prédite et son étiquette\n",
        "    intent_label = intent_labels[predicted_class]\n",
        "    return predicted_class, intent_label\n",
        "\n",
        "# Exemple d'utilisation avec une phrase personnalisée\n",
        "text_input = \"I need help with my order.\"  # Entrée utilisateur\n",
        "predicted_class, intent_label = predict_intent(text_input, model, tokenizer, device)\n",
        "\n",
        "# Affichage du résultat\n",
        "print(f\"Classe prédite : {predicted_class}, Intention : {intent_label}\")\n"
      ],
      "metadata": {
        "id": "V1qYOXworiqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Conclusion"
      ],
      "metadata": {
        "id": "efe29xfpseuH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 13.1. Résumé du projet"
      ],
      "metadata": {
        "id": "YApho5uGsh-6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans ce projet, nous avons développé un modèle de détection d'intentions basé sur **DistilBERT**, un modèle puissant et léger de la famille BERT. Les étapes principales du projet incluent :\n",
        "\n",
        "- **Prétraitement des données** : Analyse et préparation des ensembles d'entraînement, de validation et de test.\n",
        "- **Définition du modèle** : Utilisation de DistilBERT avec une tête de classification pour prédire des intentions parmi 151 classes.\n",
        "- **Entraînement et validation** : Implémentation de fonctions robustes pour l'entraînement, la validation et l'évaluation du modèle.\n",
        "- **Test final** : Évaluation des performances sur des données de test pour mesurer la précision et la capacité de généralisation.\n",
        "- **Utilisation pratique** : Test du modèle avec des données personnalisées pour démontrer son application dans des scénarios réels.\n"
      ],
      "metadata": {
        "id": "ToNmU4tBskhp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 13.2. Performances du modèle"
      ],
      "metadata": {
        "id": "Pdmyplljso1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le modèle a atteint des performances solides, avec :\n",
        "\n",
        "- Une **précision moyenne** de validation de **XX.XX%**.\n",
        "- Un rapport de classification détaillant les performances pour chaque classe d'intention.\n",
        "- Une évaluation finale sur le jeu de test confirmant sa capacité à généraliser.\n",
        "\n",
        "> Les résultats obtenus montrent que le modèle est capable de détecter efficacement les intentions, même sur des ensembles de données complexes.\n"
      ],
      "metadata": {
        "id": "A_eeuXYtsw5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 13.3. Points forts"
      ],
      "metadata": {
        "id": "tNdXaWADs3J1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Utilisation de DistilBERT** : Réduction des ressources nécessaires tout en maintenant de bonnes performances.\n",
        "- **Approche modulaire** : Les fonctions sont bien structurées, permettant une réutilisation et une extension faciles.\n",
        "- **Test avec des données réelles** : Validation de l'applicabilité du modèle dans des cas pratiques.\n"
      ],
      "metadata": {
        "id": "IhzIHUgGs8MJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 13.4. Limites et pistes d'amélioration"
      ],
      "metadata": {
        "id": "YdGvV_nOtKAK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bien que le modèle ait donné des résultats satisfaisants, certaines limites subsistent :\n",
        "\n",
        "- **Données déséquilibrées** : Certaines classes d'intention ont moins d'exemples, ce qui peut affecter les performances pour ces classes.\n",
        "- **Temps de traitement** : Bien que DistilBERT soit plus rapide que BERT, les prédictions sur de grandes quantités de données peuvent encore être optimisées.\n",
        "\n",
        "Pour aller plus loin, plusieurs améliorations pourraient être envisagées :\n",
        "\n",
        "1. **Augmentation des données** : Utiliser des techniques d'augmentation de données pour enrichir les classes sous-représentées.\n",
        "2. **Modèles avancés** : Expérimenter avec d'autres modèles, comme RoBERTa ou des architectures spécifiques aux intentions.\n",
        "3. **Optimisation** : Appliquer des techniques comme la quantification ou le pruning pour accélérer les prédictions sur des appareils avec des ressources limitées.\n",
        "4. **Intégration d'une interface utilisateur** : Développer une interface web ou mobile pour rendre l'outil accessible aux utilisateurs finaux.\n"
      ],
      "metadata": {
        "id": "sbVtJPl2tMIy"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "Y4pieq1fF2jn",
        "6j6gTIe3F9Xx",
        "Fe2PnJ9MGD5s",
        "9ZPaceGOGkue",
        "nrXx7dLAGt9i",
        "InCegYDIG51i",
        "gubB0Ov1K0WJ",
        "PhXYjFlAMtva"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}